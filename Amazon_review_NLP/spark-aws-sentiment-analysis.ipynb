{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import rand, udf, col\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.util import ngrams\n",
    "from nltk import pos_tag\n",
    "from nltk import RegexpParser\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize spark instance\n",
    "spark = SparkSession.builder.appName('Lecture').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load review data file from AWS S3\n",
    "df = spark.read.json('reviews_Musical_Instruments_5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      "\n",
      "+-------+-----+\n",
      "|overall|count|\n",
      "+-------+-----+\n",
      "|    1.0|  217|\n",
      "|    4.0| 2084|\n",
      "|    3.0|  772|\n",
      "|    2.0|  250|\n",
      "|    5.0| 6938|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Data cleanup\n",
    "#keep only overall rating and review text columns:\n",
    "review = df.select('overall','reviewText')\n",
    "review.printSchema()\n",
    "cnt = review.groupby('overall').count()\n",
    "cnt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n"
     ]
    }
   ],
   "source": [
    "cnt_dict = dict(cnt.collect())\n",
    "balanced_size = min(cnt_dict[1.0],cnt_dict[5.0])\n",
    "print(balanced_size)\n",
    "\n",
    "review_1 = review.filter(review['overall']=='1.0').orderBy(rand()).limit(balanced_size)\n",
    "review_5 = review.filter(review['overall']=='5.0').orderBy(rand()).limit(balanced_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|overall|          reviewText|\n",
      "+-------+--------------------+\n",
      "|    1.0|I am a long-time ...|\n",
      "|    1.0|I bought one of e...|\n",
      "|    1.0|At the time I bou...|\n",
      "|    1.0|I might have done...|\n",
      "|    1.0|It was Not what I...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+--------------------+\n",
      "|overall|          reviewText|\n",
      "+-------+--------------------+\n",
      "|    5.0|It's as good as i...|\n",
      "|    5.0|To everyone who p...|\n",
      "|    5.0|A great add on to...|\n",
      "|    5.0|Nice microphone s...|\n",
      "|    5.0|I typically use p...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+--------------------+-----+\n",
      "|overall|          reviewText|label|\n",
      "+-------+--------------------+-----+\n",
      "|    1.0|I am a long-time ...|  0.0|\n",
      "|    1.0|I bought one of e...|  0.0|\n",
      "|    1.0|At the time I bou...|  0.0|\n",
      "|    1.0|I might have done...|  0.0|\n",
      "|    1.0|It was Not what I...|  0.0|\n",
      "+-------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_1.show(5)\n",
    "review_5.show(5)\n",
    "review_comb = review_1.union(review_5)\n",
    "review_w_label = review_comb.withColumn('label',(review_comb['overall']-1)/4)\n",
    "review_w_label.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_bow_from_raw_text(text_as_string):\n",
    "    \"\"\"Extracts bag-of-words from a raw text string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    text (str): a text document given as a string\n",
    "    Returns\n",
    "    -------\n",
    "    list : the list of the tokens extracted and filtered from the text\n",
    "    \"\"\"\n",
    "    if (text_as_string == None):\n",
    "        return []\n",
    "\n",
    "    if (len(text_as_string) < 1):\n",
    "        return []\n",
    "\n",
    "    if sys.version_info[0] < 3:\n",
    "        nfkd_form = unicodedata.normalize('NFKD', unicode(text_as_string))\n",
    "    else:\n",
    "        nfkd_form = unicodedata.normalize('NFKD', str(text_as_string))\n",
    "\n",
    "    text_input = str(nfkd_form.encode('ASCII', 'ignore'))\n",
    "\n",
    "    sent_tokens = sent_tokenize(text_input)\n",
    "\n",
    "    tokens = list(map(word_tokenize, sent_tokens))\n",
    "\n",
    "    sent_tags = list(map(pos_tag, tokens))\n",
    "\n",
    "    grammar = r\"\"\"\n",
    "        SENT: {<(J|N).*>}                # chunk sequences of proper nouns\n",
    "    \"\"\"\n",
    "\n",
    "    cp = RegexpParser(grammar)\n",
    "    ret_tokens = list()\n",
    "    stemmer_snowball = SnowballStemmer('english')\n",
    "\n",
    "    for sent in sent_tags:\n",
    "        tree = cp.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'SENT':\n",
    "                t_tokenlist = [tpos[0].lower() for tpos in subtree.leaves()]\n",
    "                t_tokens_stemsnowball = list(map(stemmer_snowball.stem, t_tokenlist))\n",
    "                #t_token = \"-\".join(t_tokens_stemsnowball)\n",
    "                #ret_tokens.append(t_token)\n",
    "                ret_tokens.extend(t_tokens_stemsnowball)\n",
    "            #if subtree.label() == 'V2V': print(subtree)\n",
    "    #tokens_lower = [map(string.lower, sent) for sent in tokens]\n",
    "\n",
    "    return(ret_tokens)\n",
    "\n",
    "\n",
    "def indexing_pipeline(input_df, **kwargs):\n",
    "    \"\"\"Runs a full text indexing pipeline on a collection of texts contained in a DataFrame.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_df (DataFrame): a DataFrame that contains a field called 'text'\n",
    "    Returns\n",
    "    -------\n",
    "    df : the same DataFrames with a column called 'features' for each document\n",
    "    wordlist : the list of words in the vocabulary with their corresponding IDF\n",
    "    \"\"\"\n",
    "    inputCol_ = kwargs.get(\"inputCol\", \"text\")\n",
    "    vocabSize_ = kwargs.get(\"vocabSize\", 5000)\n",
    "    minDF_ = kwargs.get(\"minDF\", 2.0)\n",
    "\n",
    "    # ugly: to add that to our slave nodes so that it finds the bootstrapped nltk_data\n",
    "    nltk.data.path.append('/home/hadoop/nltk_data')\n",
    "\n",
    "    extract_bow_from_raw_text(\"\")  # ugly: for instanciating all dependencies of this function\n",
    "    tokenizer_udf = udf(extract_bow_from_raw_text, ArrayType(StringType()))\n",
    "    df_tokens = input_df.withColumn(\"bow\", tokenizer_udf(col(inputCol_)))\n",
    "\n",
    "    cv = CountVectorizer(inputCol=\"bow\", outputCol=\"vector_tf\", vocabSize=vocabSize_, minDF=minDF_)\n",
    "    cv_model = cv.fit(df_tokens)\n",
    "    df_features_tf = cv_model.transform(df_tokens)\n",
    "\n",
    "    idf = IDF(inputCol=\"vector_tf\", outputCol=\"features\")\n",
    "    idfModel = idf.fit(df_features_tf)\n",
    "    df_features = idfModel.transform(df_features_tf)\n",
    "\n",
    "    return(df_features, cv_model.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- bow: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- vector_tf: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "vocabulary: ['guitar', 'b', 'string', 'pedal', 'good', 'sound', 'great', 'other', 'amp', 'time']\n"
     ]
    }
   ],
   "source": [
    "review_out, vocab =indexing_pipeline(review_w_label, inputCol = 'reviewText')\n",
    "review_out.printSchema()\n",
    "print('vocabulary: {}'.format(vocab[:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278 156\n",
      "root\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- bow: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- vector_tf: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit Naive Bayes model\n",
    "train, test = review_out.randomSplit([0.7,0.3])\n",
    "train.persist()\n",
    "print (train.count(), test.count())\n",
    "\n",
    "NB=NaiveBayes(featuresCol = 'features', labelCol = 'label' )\n",
    "m= NB.fit(train)\n",
    "results = m.transform(test)\n",
    "\n",
    "results.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7628205128205128"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.evaluate(results.select('prediction','label'),{evaluator.metricName: 'accuracy'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = m.theta.toArray().T\n",
    "exp_theta = np.exp(theta)\n",
    "\n",
    "#calculate likelihood:\n",
    "prob_neg = exp_theta[:,0] *(1-exp_theta[:,1])\n",
    "prob_pos = exp_theta[:,1] *(1-exp_theta[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 20 words related to positive/negative reviews:\n",
    "pos_reviews = np.array(vocab)[np.argsort(prob_pos)[-20:][::-1]]\n",
    "neg_reviews = np.array(vocab)[np.argsort(prob_neg)[-20:][::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pedal', 'great', 'string', 'guitar', 'sound', 'price', 'tuner',\n",
       "       'i\\\\', 'acoust', 'good', 'pick', 'qualiti', 'amp', 'nice', 'fx',\n",
       "       'mic', 'time', 'other', 'best', 'elixir'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['guitar', 'amp', 'other', 'strap', 'problem', 'plug', 'pedal',\n",
       "       'mic', 'string', 'cheap', 'product', 'i', 'cabl', 'sound', 'issu',\n",
       "       'way', 'time', 'stand', 'pickup', 'thing'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at both positive and negative review lists of words, we can observe some clear words related to both feelings such as \"great\",\"nice\",\"best\" for positive reviews and \"problem\", \"cheap\",\"issu(e)\" for negative reviews. \n",
    "\n",
    "Note that in order to keep a balanced sample with 1 and 5 star reviews, we used the lower number of 217 reviews for the 1 star, which significantly shrank our sample. We could potentially include 2 and 3 star reviews in order to increase the overall sample size, which might show slightly different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
